{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make slurm files required to produce SXDS joint VISTA-HSC data product.\n",
    "\n",
    "In this notebook we will make all the slurm files required to run the whole VISTA-VIDEO HSC-DUD joint photometry pipeline.\n",
    "\n",
    "We need to find all the patches in the HSC imaging and produce a slurm pipeline file for every patch or group of patches.\n",
    "\n",
    "This will be a maximum of around 4 tracts * 91 patches per tract = 364 patches\n",
    "\n",
    "We will also need to set up the data directories including linking relevant reference catalogues and copying the required HSC data products which are already processed.\n",
    "\n",
    "NOTE: When running the array jobs I am using wildcards to map the index to a given shell script. This is dangerous if you have multiple versions of the slurm scripts as multiple files might have the id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table, Column\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSC_LOC = '../../dmu0/dmu0_HSC/data'\n",
    "#WORK_DIR = '/home/ir-shir1/lsst-ir-fusion/dmu4/dmu4_SXDS'\n",
    "#WORK_DIR = os. getcwd()\n",
    "WORK_DIR = '/home/ir-shir1/rds/rds-iris-ip005/ras81/lsst-ir-fusion/dmu4/dmu4_SXDS'\n",
    "MAKE_INDIVIDUAL_SLURM=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ims = Table.read('../../dmu1/data/video_images_overview_20200820.csv')\n",
    "hsc_ims = Table.read('../../dmu1/data/hsc_images_overview.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Find all the relevant HSC SXDS patches and corresponding VIDEO images.\n",
    "\n",
    "The first stage is parallesised by ccd. We will create one job for every date. This should be small enough to fit in a 24hr job.\n",
    "\n",
    "### 1.1 Get the HSC DUD files in SXDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sxds_tracts = [8282,8283,8284,8523,8524,8525,8765,8766,8767] #manually got these from HSC DR2 pages\n",
    "hsc_bands = ['G', 'R', 'I', 'Z', 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsc_ims['tract'] = [f.split('/')[14] for f in hsc_ims['file']]\n",
    "hsc_ims['patch'] = [f.split('/')[15] for f in hsc_ims['file']]\n",
    "hsc_ims['depth'] = [f.split('/')[11] for f in hsc_ims['file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sxds = hsc_ims['depth'] == 'pdr2_dud' \n",
    "in_sxds &= np.isin([int(t) for t in hsc_ims['tract'] ],  sxds_tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1629"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(in_sxds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=5</i>\n",
       "<table id=\"table4723337104\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>file</th><th>ra_0_0</th><th>ra_0_y</th><th>ra_x_0</th><th>ra_x_y</th><th>dec_0_0</th><th>dec_0_y</th><th>dec_x_0</th><th>dec_x_y</th><th>size</th><th>hash</th><th>tract</th><th>patch</th><th>depth</th></tr></thead>\n",
       "<thead><tr><th>str164</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>str32</th><th>str5</th><th>str3</th><th>str9</th></tr></thead>\n",
       "<tr><td>/home/ir-shir1/rds/rds-iris-ip005/data/public/HSC/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-Z/8765/0,0/calexp-HSC-Z-8765-0,0.fits</td><td>35.057390881574044</td><td>35.05720789563249</td><td>34.865503651256965</td><td>34.86536233311517</td><td>-4.558457292032212</td><td>-4.367177057413561</td><td>-4.558655394587739</td><td>-4.367366830731112</td><td>210075840</td><td>93e4be0f6ccbf4f282001d491f830060</td><td>8765</td><td>0,0</td><td>pdr2_dud</td></tr>\n",
       "<tr><td>/home/ir-shir1/rds/rds-iris-ip005/data/public/HSC/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-Z/8765/2,2/calexp-HSC-Z-8765-2,2.fits</td><td>34.68744599488356</td><td>34.687340888143005</td><td>34.490935877105265</td><td>34.49087447536722</td><td>-4.19018894495259</td><td>-3.9942041159656037</td><td>-4.190282501066741</td><td>-3.994293285659841</td><td>149581440</td><td>bb471cb691de84ed694a8179c780c4da</td><td>8765</td><td>2,2</td><td>pdr2_dud</td></tr>\n",
       "<tr><td>/home/ir-shir1/rds/rds-iris-ip005/data/public/HSC/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-Z/8765/0,6/calexp-HSC-Z-8765-0,6.fits</td><td>35.05632532497644</td><td>35.05613835071305</td><td>34.864680733040856</td><td>34.864536334791445</td><td>-3.4433065839296444</td><td>-3.2473362428975334</td><td>-3.4434561168248923</td><td>-3.2474772402754106</td><td>64304640</td><td>bddc980e7d6fc6007a039863e628abad</td><td>8765</td><td>0,6</td><td>pdr2_dud</td></tr>\n",
       "<tr><td>/home/ir-shir1/rds/rds-iris-ip005/data/public/HSC/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-Z/8765/1,3/calexp-HSC-Z-8765-1,3.fits</td><td>34.87444848193645</td><td>34.87430182037414</td><td>34.677990464977505</td><td>34.67788748292052</td><td>-4.003408172084183</td><td>-3.8074234215277722</td><td>-4.003542229270651</td><td>-3.807550898996197</td><td>130622400</td><td>28975127e02dcd2d11576f7aa3911d6b</td><td>8765</td><td>1,3</td><td>pdr2_dud</td></tr>\n",
       "<tr><td>/home/ir-shir1/rds/rds-iris-ip005/data/public/HSC/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-Z/8765/3,0/calexp-HSC-Z-8765-3,0.fits</td><td>34.50041317080672</td><td>34.500351147036746</td><td>34.30381449491872</td><td>34.30379517560638</td><td>-4.558891715533787</td><td>-4.367593215541012</td><td>-4.558942620240526</td><td>-4.367641979954217</td><td>198616320</td><td>7939cb9d2256af91b2e55dbe826edacc</td><td>8765</td><td>3,0</td><td>pdr2_dud</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "                                                                               file                                                                               ...\n",
       "                                                                              str164                                                                              ...\n",
       "----------------------------------------------------------------------------------------------------------------------------------------------------------------- ...\n",
       "/home/ir-shir1/rds/rds-iris-ip005/data/public/HSC/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-Z/8765/0,0/calexp-HSC-Z-8765-0,0.fits ...\n",
       "/home/ir-shir1/rds/rds-iris-ip005/data/public/HSC/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-Z/8765/2,2/calexp-HSC-Z-8765-2,2.fits ...\n",
       "/home/ir-shir1/rds/rds-iris-ip005/data/public/HSC/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-Z/8765/0,6/calexp-HSC-Z-8765-0,6.fits ...\n",
       "/home/ir-shir1/rds/rds-iris-ip005/data/public/HSC/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-Z/8765/1,3/calexp-HSC-Z-8765-1,3.fits ...\n",
       "/home/ir-shir1/rds/rds-iris-ip005/data/public/HSC/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-Z/8765/3,0/calexp-HSC-Z-8765-3,0.fits ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsc_ims[in_sxds][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Find VIDEO images containing those patches\n",
    "\n",
    "To begin we simply find all tiles which contain the centres of any of those patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ims.add_column(Column(\n",
    "    data= [t.split('/')[-2] for t in video_ims['file']],\n",
    "    name='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ims.sort('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileToType(filename):\n",
    "    filetype = ''\n",
    "    types = {\n",
    "        'tile':'_tl.fit',\n",
    "        'stack':'_st.fit',\n",
    "    }\n",
    "    for k,v in types.items():\n",
    "        #print(k,v)\n",
    "        if filename.endswith(v):\n",
    "            filetype = k\n",
    "       \n",
    "    return filetype\n",
    "video_ims['type'] = [fileToType(f) for f in video_ims['file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00444'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = '/home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/20140924/v20140924_00444_st_tl.fit'\n",
    "f.split('/')[-1].split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ims['obsNum'] = [f.split('/')[-1].split('_')[1] for f in video_ims['file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rs548/GitHub/lsst_stack/conda/miniconda3-py37_4.8.2/envs/lsst-scipipe-1a1d771/lib/python3.7/site-packages/astropy/table/column.py:1020: RuntimeWarning: invalid value encountered in greater\n",
      "  result = getattr(super(), op)(other)\n",
      "/Users/rs548/GitHub/lsst_stack/conda/miniconda3-py37_4.8.2/envs/lsst-scipipe-1a1d771/lib/python3.7/site-packages/astropy/table/column.py:1020: RuntimeWarning: invalid value encountered in less\n",
      "  result = getattr(super(), op)(other)\n"
     ]
    }
   ],
   "source": [
    "#TODO make more sophisticated overlap tester. Use patches?\n",
    "#make list of patches for every tile?\n",
    "near_sxds = video_ims['type'] == 'tile'\n",
    "near_sxds &= video_ims['ra'] > 32 #generous bounding box for simplicity \n",
    "near_sxds &= video_ims['ra'] < 39\n",
    "near_sxds &= video_ims['dec'] > -8\n",
    "near_sxds &= video_ims['dec'] < -1\n",
    "#Just run Ks for now\n",
    "#near_sxds &= video_ims['filter'] == 'Ks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "863"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(near_sxds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks_near =  video_ims['type'] == 'stack'\n",
    "stacks_near &= video_ims['ra'] > 32 #generous bounding box for simplicity \n",
    "stacks_near &= video_ims['ra'] < 39\n",
    "stacks_near &= video_ims['dec'] > -8\n",
    "stacks_near &= video_ims['dec'] < -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5263"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(stacks_near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=5</i>\n",
       "<table id=\"table4735804688\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>file</th><th>ra</th><th>dec</th><th>ra_0_0</th><th>ra_0_y</th><th>ra_x_0</th><th>ra_x_y</th><th>dec_0_0</th><th>dec_0_y</th><th>dec_x_0</th><th>dec_x_y</th><th>filter</th><th>size</th><th>hash</th><th>date</th><th>type</th><th>obsNum</th></tr></thead>\n",
       "<thead><tr><th>str98</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str2</th><th>int64</th><th>str32</th><th>str8</th><th>str5</th><th>str9</th></tr></thead>\n",
       "<tr><td>/home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/20091103/v20091103_00361_st_tl.fit</td><td>36.482612</td><td>-4.64011</td><td>37.18446376283541</td><td>37.18671068481155</td><td>35.96142569129426</td><td>35.96102830361003</td><td>-3.9850258075845617</td><td>-5.479635485470843</td><td>-3.985350448863505</td><td>-5.479961751382123</td><td>H</td><td>211245120</td><td>4648bb5a2551a9d253274695d8709dc4</td><td>20091103</td><td>tile</td><td>00361</td></tr>\n",
       "<tr><td>/home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/20091103/v20091103_00319_st_tl.fit</td><td>36.484112</td><td>-4.64001</td><td>37.18244205557211</td><td>37.184923290765525</td><td>35.96380494458813</td><td>35.96365718102102</td><td>-3.985523268154244</td><td>-5.477145669021565</td><td>-3.985969141347432</td><td>-5.47759358412129</td><td>H</td><td>210323520</td><td>086fdef775bddc65aecb10681353e7a5</td><td>20091103</td><td>tile</td><td>00319</td></tr>\n",
       "<tr><td>/home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/20091104/v20091104_00319_st_tl.fit</td><td>36.483812</td><td>-4.64101</td><td>37.185103418076025</td><td>37.187436198004626</td><td>35.96987084120229</td><td>35.96957738108382</td><td>-3.987062767568743</td><td>-5.48050748024346</td><td>-3.9875552242675147</td><td>-5.481001717657909</td><td>H</td><td>214657920</td><td>21e051338680f47dd231334be2772c18</td><td>20091104</td><td>tile</td><td>00319</td></tr>\n",
       "<tr><td>/home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/20091104/v20091104_00277_st_tl.fit</td><td>36.484412</td><td>-4.63991</td><td>37.185832546025814</td><td>37.188199421866024</td><td>35.96532041029172</td><td>35.96505090160476</td><td>-3.9869434620063644</td><td>-5.479807283391449</td><td>-3.9874028647210977</td><td>-5.4802685254066645</td><td>H</td><td>216878400</td><td>4bc5a0910a23de57e47f8406d2debd0d</td><td>20091104</td><td>tile</td><td>00277</td></tr>\n",
       "<tr><td>/home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/20091104/v20091104_00215_st_tl.fit</td><td>36.484112</td><td>-4.64021</td><td>37.18350458780609</td><td>37.18605323213357</td><td>35.962919768414295</td><td>35.96283111308644</td><td>-3.986760882421296</td><td>-5.48004219108339</td><td>-3.9872372826651907</td><td>-5.480520748714671</td><td>H</td><td>222361920</td><td>d238bcab5052c04d18f6442ae82d0fc9</td><td>20091104</td><td>tile</td><td>00215</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "                                             file                                             ...\n",
       "                                            str98                                             ...\n",
       "--------------------------------------------------------------------------------------------- ...\n",
       "/home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/20091103/v20091103_00361_st_tl.fit ...\n",
       "/home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/20091103/v20091103_00319_st_tl.fit ...\n",
       "/home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/20091104/v20091104_00319_st_tl.fit ...\n",
       "/home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/20091104/v20091104_00277_st_tl.fit ...\n",
       "/home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/20091104/v20091104_00215_st_tl.fit ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_ims[near_sxds][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: ./data/sxds_tiles.csv already exists. Automatically overwriting ASCII files is deprecated. Use the argument 'overwrite=True' in the future. [astropy.io.ascii.ui]\n"
     ]
    }
   ],
   "source": [
    "video_ims[near_sxds].write('./data/sxds_tiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For simplicity lets ingest all the images (They are only links and this stage is fast)\n",
    "#!mkdir data\n",
    "#!mkdir slurm\n",
    "#!ingestImages.py data /home/ir-shir1/rds/rds-iris-ip005/data/private/VISTA/VIDEO/*/*_st.fit #Stacks\n",
    "#for date in date_list:\n",
    "#    #!ingestImages.py data /path/to/vista/{date}/*[0-9].fit #Exposures\n",
    "#    !ingestImages.py data /path/to/vista/{date}/*_st.fit #Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_list = ['20121122', '20171027'] #test dates\n",
    "date_list = np.unique(video_ims['date'][near_sxds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7903"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of stack files in total tile date list\n",
    "np.sum(np.isin(video_ims['date'][video_ims['type'] == 'stack'], date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = [date[0:4]+'-'+date[4:6]+'-'+date[6:9] for date in date_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2009-11-03',\n",
       " '2009-11-04',\n",
       " '2009-11-05',\n",
       " '2009-11-06',\n",
       " '2009-11-07',\n",
       " '2009-11-08',\n",
       " '2009-11-10',\n",
       " '2009-11-11',\n",
       " '2009-11-12',\n",
       " '2009-11-13',\n",
       " '2009-11-16',\n",
       " '2009-11-17',\n",
       " '2009-12-03',\n",
       " '2009-12-04',\n",
       " '2009-12-05',\n",
       " '2009-12-06',\n",
       " '2009-12-07',\n",
       " '2009-12-08',\n",
       " '2009-12-09',\n",
       " '2009-12-10',\n",
       " '2009-12-11',\n",
       " '2009-12-12',\n",
       " '2009-12-15',\n",
       " '2009-12-16',\n",
       " '2009-12-17',\n",
       " '2009-12-20',\n",
       " '2009-12-21',\n",
       " '2009-12-22',\n",
       " '2009-12-24',\n",
       " '2009-12-29',\n",
       " '2010-01-03',\n",
       " '2010-01-04',\n",
       " '2010-01-07',\n",
       " '2010-01-08',\n",
       " '2010-01-12',\n",
       " '2010-01-16',\n",
       " '2010-01-17',\n",
       " '2010-01-26',\n",
       " '2010-01-28',\n",
       " '2010-01-29',\n",
       " '2010-01-30',\n",
       " '2010-01-31',\n",
       " '2010-02-02',\n",
       " '2010-07-21',\n",
       " '2010-07-24',\n",
       " '2010-07-27',\n",
       " '2010-07-28',\n",
       " '2010-08-04',\n",
       " '2010-08-05',\n",
       " '2010-08-07',\n",
       " '2010-08-08',\n",
       " '2010-08-14',\n",
       " '2010-08-15',\n",
       " '2010-08-16',\n",
       " '2010-08-17',\n",
       " '2010-08-19',\n",
       " '2010-08-24',\n",
       " '2010-08-25',\n",
       " '2010-08-26',\n",
       " '2010-09-09',\n",
       " '2010-09-10',\n",
       " '2010-09-11',\n",
       " '2010-09-13',\n",
       " '2010-09-14',\n",
       " '2010-09-15',\n",
       " '2010-09-19',\n",
       " '2010-09-20',\n",
       " '2010-09-22',\n",
       " '2010-09-23',\n",
       " '2010-10-07',\n",
       " '2010-10-08',\n",
       " '2010-10-09',\n",
       " '2010-10-14',\n",
       " '2010-10-15',\n",
       " '2010-10-17',\n",
       " '2010-10-18',\n",
       " '2010-10-19',\n",
       " '2010-10-26',\n",
       " '2010-10-29',\n",
       " '2010-11-01',\n",
       " '2010-11-02',\n",
       " '2010-11-06',\n",
       " '2010-11-07',\n",
       " '2010-11-26',\n",
       " '2010-11-27',\n",
       " '2010-11-28',\n",
       " '2010-12-01',\n",
       " '2010-12-03',\n",
       " '2010-12-04',\n",
       " '2010-12-06',\n",
       " '2010-12-07',\n",
       " '2010-12-08',\n",
       " '2010-12-09',\n",
       " '2010-12-10',\n",
       " '2010-12-19',\n",
       " '2010-12-20',\n",
       " '2010-12-21',\n",
       " '2010-12-22',\n",
       " '2010-12-27',\n",
       " '2011-01-05',\n",
       " '2011-01-06',\n",
       " '2011-01-23',\n",
       " '2011-01-24',\n",
       " '2011-07-24',\n",
       " '2011-08-03',\n",
       " '2011-08-04',\n",
       " '2011-08-05',\n",
       " '2011-08-06',\n",
       " '2011-08-08',\n",
       " '2011-08-09',\n",
       " '2011-08-25',\n",
       " '2011-08-29',\n",
       " '2011-08-30',\n",
       " '2011-08-31',\n",
       " '2011-09-02',\n",
       " '2011-09-06',\n",
       " '2011-09-24',\n",
       " '2011-09-25',\n",
       " '2011-09-27',\n",
       " '2011-10-01',\n",
       " '2011-10-02',\n",
       " '2011-10-03',\n",
       " '2011-10-04',\n",
       " '2011-10-05',\n",
       " '2011-10-08',\n",
       " '2011-10-19',\n",
       " '2011-10-20',\n",
       " '2011-10-22',\n",
       " '2011-10-24',\n",
       " '2011-10-25',\n",
       " '2011-10-27',\n",
       " '2011-10-28',\n",
       " '2011-10-29',\n",
       " '2011-10-30',\n",
       " '2011-10-31',\n",
       " '2011-11-01',\n",
       " '2011-11-02',\n",
       " '2011-11-04',\n",
       " '2011-11-05',\n",
       " '2011-11-15',\n",
       " '2011-11-17',\n",
       " '2011-11-18',\n",
       " '2011-11-20',\n",
       " '2011-11-22',\n",
       " '2011-11-24',\n",
       " '2011-11-25',\n",
       " '2011-11-26',\n",
       " '2011-11-27',\n",
       " '2011-12-01',\n",
       " '2011-12-19',\n",
       " '2011-12-31',\n",
       " '2012-07-07',\n",
       " '2012-07-17',\n",
       " '2012-07-22',\n",
       " '2012-07-23',\n",
       " '2012-08-21',\n",
       " '2012-08-24',\n",
       " '2012-08-27',\n",
       " '2012-08-30',\n",
       " '2012-09-07',\n",
       " '2012-09-10',\n",
       " '2012-09-12',\n",
       " '2012-09-13',\n",
       " '2012-09-16',\n",
       " '2012-09-19',\n",
       " '2012-09-20',\n",
       " '2012-09-21',\n",
       " '2012-09-24',\n",
       " '2012-09-25',\n",
       " '2012-10-09',\n",
       " '2012-10-10',\n",
       " '2012-10-11',\n",
       " '2012-10-14',\n",
       " '2012-10-15',\n",
       " '2012-10-17',\n",
       " '2012-10-18',\n",
       " '2012-10-19',\n",
       " '2012-10-20',\n",
       " '2012-10-21',\n",
       " '2012-10-22',\n",
       " '2012-10-23',\n",
       " '2012-10-24',\n",
       " '2012-10-25',\n",
       " '2012-11-02',\n",
       " '2012-11-03',\n",
       " '2012-11-04',\n",
       " '2012-11-06',\n",
       " '2012-11-07',\n",
       " '2012-11-08',\n",
       " '2012-11-09',\n",
       " '2012-11-10',\n",
       " '2012-11-11',\n",
       " '2012-11-12',\n",
       " '2012-11-15',\n",
       " '2012-11-16',\n",
       " '2012-11-17',\n",
       " '2012-11-18',\n",
       " '2012-11-19',\n",
       " '2012-11-20',\n",
       " '2012-11-21',\n",
       " '2012-11-22',\n",
       " '2012-11-27',\n",
       " '2012-11-29',\n",
       " '2012-11-30',\n",
       " '2012-12-01',\n",
       " '2012-12-02',\n",
       " '2012-12-03',\n",
       " '2012-12-04',\n",
       " '2012-12-05',\n",
       " '2012-12-06',\n",
       " '2012-12-07',\n",
       " '2013-01-06',\n",
       " '2013-01-11',\n",
       " '2013-08-04',\n",
       " '2013-08-10',\n",
       " '2013-08-13',\n",
       " '2013-08-14',\n",
       " '2013-08-15',\n",
       " '2013-08-16',\n",
       " '2013-08-17',\n",
       " '2013-08-30',\n",
       " '2013-09-03',\n",
       " '2013-09-07',\n",
       " '2013-09-12',\n",
       " '2013-09-13',\n",
       " '2013-09-28',\n",
       " '2013-09-29',\n",
       " '2013-10-01',\n",
       " '2013-10-03',\n",
       " '2013-10-07',\n",
       " '2013-10-10',\n",
       " '2013-10-11',\n",
       " '2013-10-13',\n",
       " '2013-10-26',\n",
       " '2013-10-27',\n",
       " '2013-10-28',\n",
       " '2013-10-30',\n",
       " '2013-10-31',\n",
       " '2013-11-02',\n",
       " '2013-11-03',\n",
       " '2013-11-04',\n",
       " '2013-11-05',\n",
       " '2013-11-06',\n",
       " '2013-11-07',\n",
       " '2013-11-09',\n",
       " '2013-11-12',\n",
       " '2013-11-22',\n",
       " '2013-11-24',\n",
       " '2013-11-25',\n",
       " '2013-11-26',\n",
       " '2013-11-27',\n",
       " '2013-11-28',\n",
       " '2013-11-30',\n",
       " '2013-12-05',\n",
       " '2013-12-07',\n",
       " '2013-12-09',\n",
       " '2013-12-10',\n",
       " '2013-12-17',\n",
       " '2013-12-18',\n",
       " '2013-12-19',\n",
       " '2013-12-20',\n",
       " '2013-12-22',\n",
       " '2013-12-23',\n",
       " '2013-12-26',\n",
       " '2013-12-27',\n",
       " '2013-12-29',\n",
       " '2013-12-30',\n",
       " '2013-12-31',\n",
       " '2014-01-01',\n",
       " '2014-01-02',\n",
       " '2014-01-03',\n",
       " '2014-07-08',\n",
       " '2014-07-28',\n",
       " '2014-07-30',\n",
       " '2014-08-05',\n",
       " '2014-08-24',\n",
       " '2014-08-29',\n",
       " '2014-08-31',\n",
       " '2014-09-02',\n",
       " '2014-09-09',\n",
       " '2014-09-20',\n",
       " '2014-09-21',\n",
       " '2014-09-22',\n",
       " '2014-09-24',\n",
       " '2014-09-25',\n",
       " '2014-09-27',\n",
       " '2014-09-28',\n",
       " '2014-10-01',\n",
       " '2014-10-05',\n",
       " '2014-10-06',\n",
       " '2014-10-17',\n",
       " '2014-10-20',\n",
       " '2014-10-22',\n",
       " '2014-10-23',\n",
       " '2014-10-24',\n",
       " '2014-10-27',\n",
       " '2014-10-29',\n",
       " '2014-10-30',\n",
       " '2014-10-31',\n",
       " '2014-11-01',\n",
       " '2014-11-02',\n",
       " '2014-11-03',\n",
       " '2014-11-09',\n",
       " '2014-11-15',\n",
       " '2014-11-17',\n",
       " '2014-11-18',\n",
       " '2014-11-19',\n",
       " '2014-11-21',\n",
       " '2014-11-22',\n",
       " '2014-11-23',\n",
       " '2014-11-25',\n",
       " '2014-11-26',\n",
       " '2014-11-27',\n",
       " '2014-11-28',\n",
       " '2014-11-29',\n",
       " '2014-11-30',\n",
       " '2014-12-12',\n",
       " '2014-12-13',\n",
       " '2014-12-14',\n",
       " '2014-12-16',\n",
       " '2014-12-17',\n",
       " '2015-09-08',\n",
       " '2015-09-11',\n",
       " '2015-09-14',\n",
       " '2015-09-17',\n",
       " '2015-10-02',\n",
       " '2015-10-04',\n",
       " '2015-10-05',\n",
       " '2015-10-08',\n",
       " '2015-10-10',\n",
       " '2015-10-11',\n",
       " '2015-10-15',\n",
       " '2015-10-22',\n",
       " '2015-10-28',\n",
       " '2015-10-30',\n",
       " '2015-10-31',\n",
       " '2015-11-03',\n",
       " '2015-11-04',\n",
       " '2015-11-05',\n",
       " '2015-11-06',\n",
       " '2015-11-07',\n",
       " '2015-11-08',\n",
       " '2015-11-09',\n",
       " '2015-11-11',\n",
       " '2015-11-12',\n",
       " '2015-11-13',\n",
       " '2015-11-14',\n",
       " '2015-11-18',\n",
       " '2015-12-04',\n",
       " '2015-12-05',\n",
       " '2015-12-09',\n",
       " '2015-12-11',\n",
       " '2015-12-18',\n",
       " '2016-01-10',\n",
       " '2016-07-12',\n",
       " '2016-07-14',\n",
       " '2016-07-29',\n",
       " '2016-07-31',\n",
       " '2016-08-01',\n",
       " '2016-08-02',\n",
       " '2016-08-04',\n",
       " '2016-08-12',\n",
       " '2016-08-13',\n",
       " '2016-08-30',\n",
       " '2016-08-31',\n",
       " '2016-09-01',\n",
       " '2016-09-02',\n",
       " '2016-09-03',\n",
       " '2016-09-30',\n",
       " '2016-10-01',\n",
       " '2016-10-08',\n",
       " '2016-10-09',\n",
       " '2016-10-10',\n",
       " '2016-10-22',\n",
       " '2016-10-23',\n",
       " '2016-10-28',\n",
       " '2016-10-29',\n",
       " '2016-10-30',\n",
       " '2016-10-31',\n",
       " '2016-11-02',\n",
       " '2016-11-03',\n",
       " '2017-07-02',\n",
       " '2017-07-19',\n",
       " '2017-07-26',\n",
       " '2017-08-17',\n",
       " '2017-08-18',\n",
       " '2017-08-20',\n",
       " '2017-08-21',\n",
       " '2017-08-25',\n",
       " '2017-08-30',\n",
       " '2017-08-31',\n",
       " '2017-09-15',\n",
       " '2017-09-18',\n",
       " '2017-09-19',\n",
       " '2017-09-20',\n",
       " '2017-09-21',\n",
       " '2017-09-22',\n",
       " '2017-09-23',\n",
       " '2017-09-24',\n",
       " '2017-09-27',\n",
       " '2017-09-28',\n",
       " '2017-10-17',\n",
       " '2017-10-18',\n",
       " '2017-10-19',\n",
       " '2017-10-20',\n",
       " '2017-10-21',\n",
       " '2017-10-22',\n",
       " '2017-10-23',\n",
       " '2017-10-24',\n",
       " '2017-10-25',\n",
       " '2017-10-26',\n",
       " '2017-10-27',\n",
       " '2017-11-07']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Process CCDs\n",
    "\n",
    "This stage is parallelised accroding to the raw files ingested. We are going to make one job per date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurm_template= \"\"\"#!/bin/bash\n",
    "#!\n",
    "#! Example SLURM job script for Peta4-Skylake (Skylake CPUs, OPA)\n",
    "#! Last updated: Mon 13 Nov 12:25:17 GMT 2017\n",
    "#!\n",
    "\n",
    "#!#############################################################\n",
    "#!#### Modify the options in this section as appropriate ######\n",
    "#!#############################################################\n",
    "\n",
    "#! sbatch directives begin here ###############################\n",
    "#! Name of the job:\n",
    "#SBATCH -J {job_name}\n",
    "#! Which project should be charged:\n",
    "#SBATCH -A IRIS-IP005-CPU\n",
    "#! How many whole nodes should be allocated?\n",
    "#SBATCH --nodes=1\n",
    "#! How many (MPI) tasks will there be in total? (<= nodes*32)\n",
    "#! The skylake/skylake-himem nodes have 32 CPUs (cores) each.\n",
    "#SBATCH --ntasks=1\n",
    "#! How much wallclock time will be required?\n",
    "#SBATCH --time={hours}:00:00\n",
    "#! What types of email messages do you wish to receive?\n",
    "#SBATCH --mail-type=FAIL\n",
    "#! Uncomment this to prevent the job from being requeued (e.g. if\n",
    "#! interrupted by node failure or system downtime):\n",
    "##SBATCH --no-requeue\n",
    "\n",
    "#! For 6GB per CPU, set \"-p skylake\"; for 12GB per CPU, set \"-p skylake-himem\": \n",
    "#SBATCH -p skylake\n",
    "\n",
    "#! sbatch directives end here (put any additional directives above this line)\n",
    "\n",
    "#! Notes:\n",
    "#! Charging is determined by core number*walltime.\n",
    "#! The --ntasks value refers to the number of tasks to be launched by SLURM only. This\n",
    "#! usually equates to the number of MPI tasks launched. Reduce this from nodes*32 if\n",
    "#! demanded by memory requirements, or if OMP_NUM_THREADS>1.\n",
    "#! Each task is allocated 1 core by default, and each core is allocated 5980MB (skylake)\n",
    "#! and 12030MB (skylake-himem). If this is insufficient, also specify\n",
    "#! --cpus-per-task and/or --mem (the latter specifies MB per node).\n",
    "\n",
    "#! Number of nodes and tasks per node allocated by SLURM (do not change):\n",
    "numnodes=$SLURM_JOB_NUM_NODES\n",
    "numtasks=$SLURM_NTASKS\n",
    "mpi_tasks_per_node=$(echo \"$SLURM_TASKS_PER_NODE\" | sed -e  's/^\\([0-9][0-9]*\\).*$/\\\\1/')\n",
    "#! ############################################################\n",
    "#! Modify the settings below to specify the application's environment, location \n",
    "#! and launch method:\n",
    "\n",
    "#! Optionally modify the environment seen by the application\n",
    "#! (note that SLURM reproduces the environment at submission irrespective of ~/.bashrc):\n",
    ". /etc/profile.d/modules.sh                # Leave this line (enables the module command)\n",
    "module purge                               # Removes all modules still loaded\n",
    "module load rhel7/default-peta4            # REQUIRED - loads the basic environment\n",
    "\n",
    "#! Insert additional module load commands after this line if needed:\n",
    "\n",
    "#! Full path to application executable: \n",
    "application=\"{sh_name}\"\n",
    "\n",
    "#! Run options for the application:\n",
    "options=\"\"\n",
    "\n",
    "#! Work directory (i.e. where the job will run):\n",
    "workdir=\"$SLURM_SUBMIT_DIR\"  # The value of SLURM_SUBMIT_DIR sets workdir to the directory\n",
    "                             # in which sbatch is run.\n",
    "\n",
    "#! Are you using OpenMP (NB this is unrelated to OpenMPI)? If so increase this\n",
    "#! safe value to no more than 32:\n",
    "export OMP_NUM_THREADS=1\n",
    "\n",
    "#! Number of MPI tasks to be started by the application per node and in total (do not change):\n",
    "np=$[${{numnodes}}*${{mpi_tasks_per_node}}]\n",
    "\n",
    "#! The following variables define a sensible pinning strategy for Intel MPI tasks -\n",
    "#! this should be suitable for both pure MPI and hybrid MPI/OpenMP jobs:\n",
    "export I_MPI_PIN_DOMAIN=omp:compact # Domains are $OMP_NUM_THREADS cores in size\n",
    "export I_MPI_PIN_ORDER=scatter # Adjacent domains have minimal sharing of caches/sockets\n",
    "#! Notes:\n",
    "#! 1. These variables influence Intel MPI only.\n",
    "#! 2. Domains are non-overlapping sets of cores which map 1-1 to MPI tasks.\n",
    "#! 3. I_MPI_PIN_PROCESSOR_LIST is ignored if I_MPI_PIN_DOMAIN is set.\n",
    "#! 4. If MPI tasks perform better when sharing caches/sockets, try I_MPI_PIN_ORDER=compact.\n",
    "\n",
    "\n",
    "#! Uncomment one choice for CMD below (add mpirun/mpiexec options if necessary):\n",
    "\n",
    "#! Choose this for a MPI code (possibly using OpenMP) using Intel MPI.\n",
    "CMD=\"mpirun -ppn $mpi_tasks_per_node -np $np $application $options\"\n",
    "\n",
    "#! Choose this for a pure shared-memory OpenMP parallel program on a single node:\n",
    "#! (OMP_NUM_THREADS threads will be created):\n",
    "#CMD=\"$application $options\"\n",
    "\n",
    "#! Choose this for a MPI code (possibly using OpenMP) using OpenMPI:\n",
    "#CMD=\"mpirun -npernode $mpi_tasks_per_node -np $np $application $options\"\n",
    "\n",
    "\n",
    "###############################################################\n",
    "### You should not have to change anything below this line ####\n",
    "###############################################################\n",
    "\n",
    "cd $workdir\n",
    "echo -e \"Changed directory to `pwd`.\\n\"\n",
    "\n",
    "JOBID=$SLURM_JOB_ID\n",
    "\n",
    "echo -e \"JobID: $JOBID\\n======\"\n",
    "echo \"Time: `date`\"\n",
    "echo \"Running on master node: `hostname`\"\n",
    "echo \"Current directory: `pwd`\"\n",
    "\n",
    "if [ \"$SLURM_JOB_NODELIST\" ]; then\n",
    "        #! Create a machine file:\n",
    "        export NODEFILE=`generate_pbs_nodefile`\n",
    "        cat $NODEFILE | uniq > machine.file.$JOBID\n",
    "        echo -e \"\\nNodes allocated:\\n================\"\n",
    "        echo `cat machine.file.$JOBID | sed -e 's/\\..*$//g'`\n",
    "fi\n",
    "\n",
    "echo -e \"\\nnumtasks=$numtasks, numnodes=$numnodes, mpi_tasks_per_node=$mpi_tasks_per_node (OMP_NUM_THREADS=$OMP_NUM_THREADS)\"\n",
    "\n",
    "echo -e \"\\nExecuting command:\\n==================\\n$CMD\\n\"\n",
    "\n",
    "eval $CMD \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurm_array_template=\"\"\"#!/bin/bash\n",
    "#! This line is a comment\n",
    "#! Make sure you only have comments and #SBATCH directives between here and the end of the #SBATCH directives, or things will break\n",
    "#! Name of the job:\n",
    "#SBATCH -J {job_name}\n",
    "#! Account name for group, use SL2 for paying queue:\n",
    "#SBATCH -A IRIS-IP005-CPU\n",
    "#! Output filename:\n",
    "#! %A means slurm job ID and %a means array index\n",
    "#SBATCH --output={jobNameBase}_%A_%a.out\n",
    "#! Errors filename:\n",
    "#SBATCH --error={jobNameBase}_%A_%a.err\n",
    "\n",
    "#! Number of nodes to be allocated for the job (for single core jobs always leave this at 1)\n",
    "#SBATCH --nodes=1\n",
    "#! Number of tasks. By default SLURM assumes 1 task per node and 1 CPU per task. (for single core jobs always leave this at 1)\n",
    "#SBATCH --ntasks=1\n",
    "#! How many many cores will be allocated per task? (for single core jobs always leave this at 1)\n",
    "#SBATCH --cpus-per-task=1\n",
    "#! Estimated runtime: hh:mm:ss (job is force-stopped after if exceeded):\n",
    "#SBATCH --time={hours}:00:00\n",
    "#! Estimated maximum memory needed (job is force-stopped if exceeded):\n",
    "#! RAM is allocated in ~5980mb blocks, you are charged per block used,\n",
    "#! and unused fractions of blocks will not be usable by others.\n",
    "#SBATCH --mem=5980mb\n",
    "#! Submit a job array with index values between 0 and 31\n",
    "#! NOTE: This must be a range, not a single number (i.e. specifying '32' here would only run one job, with index 32)\n",
    "#SBATCH --array={start}-{stop}\n",
    "\n",
    "#! This is the partition name.\n",
    "#SBATCH -p skylake\n",
    "\n",
    "#! mail alert at start, end and abortion of execution\n",
    "#! emails will default to going to your email address\n",
    "#! you can specify a different email address manually if needed.\n",
    "##SBATCH --mail-type=ALL\n",
    "\n",
    "#! Don't put any #SBATCH directives below this line\n",
    "\n",
    "#! Modify the environment seen by the application. For this example we need the default modules.\n",
    "\n",
    "\n",
    "#! The variable $SLURM_ARRAY_TASK_ID contains the array index for each job.\n",
    "#! In this example, each job will be passed its index, so each output file will contain a different value\n",
    "echo \"This is job\" $SLURM_ARRAY_TASK_ID\n",
    "\n",
    "#! Command line that we want to run:\n",
    "{WORK_DIR}/slurm/{jobNameBase}*_$SLURM_ARRAY_TASK_ID.sh\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_template = \"\"\"#!/bin/bash\n",
    "source /rfs/project/rfs-L33A9wsNuJk/shared/lsst_stack/loadLSST.bash\n",
    "setup lsst_distrib\n",
    "setup obs_vista\n",
    "eups admin clearLocks\n",
    "processCcd.py ../data --rerun processCcdOutputs --id dateObs={dateObs} obsNum={obsNum} --clobber-config\n",
    "\"\"\"\n",
    "#By date:\n",
    "#processCcd.py ../data --rerun processCcdOutputs --id dateObs={obsDate} --clobber-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= 0\n",
    "for im in video_ims[stacks_near]: #date_list:\n",
    "    date = im['date']\n",
    "    dateObs = date[0:4]+'-'+date[4:6]+'-'+date[6:9]\n",
    "    obsNum = im['obsNum']\n",
    "    job_name = \"processCcd_{}_{}_{}\".format(dateObs, obsNum, n)\n",
    "    f_sh = open('./slurm/' + job_name + '.sh', \"w+\")\n",
    "    f_sh.write(sh_template.format(dateObs=dateObs, obsNum=obsNum))\n",
    "    f_sh.close()\n",
    "    if MAKE_INDIVIDUAL_SLURM:\n",
    "        f_slurm = open('./slurm/' + job_name + '.slurm', \"w+\")\n",
    "        f_slurm.write(slurm_template.format(\n",
    "            job_name=job_name,\n",
    "            hours='1',\n",
    "            jobNameBase=WORK_DIR + '/slurm/' + job_name + '.sh'\n",
    "        ))\n",
    "        f_slurm.close()\n",
    "    n+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5263"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "block_size = 100\n",
    "for block in range(int(np.ceil(n/block_size))):\n",
    "    start=block*block_size\n",
    "    stop =np.min([n+1, (block+1)*block_size]) -1\n",
    "    jobNameBase='processCcd'\n",
    "    job_name = jobNameBase + '_array_{}-{}'.format(start, stop)\n",
    "    slurm_filename = './slurm/'+job_name+'.slurm'\n",
    "    array_slurm = open(slurm_filename, \"w+\")\n",
    "    array_slurm.write(slurm_array_template.format(\n",
    "        job_name=job_name,\n",
    "        hours='36',\n",
    "        start=start,\n",
    "        stop=stop,\n",
    "        WORK_DIR=WORK_DIR,\n",
    "        jobNameBase=jobNameBase\n",
    "    ))\n",
    "    array_slurm.close()\n",
    "    print(slurm_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./slurm/processCcd_array_all_0-5263.slurm\n"
     ]
    }
   ],
   "source": [
    "jobNameBase='processCcd'\n",
    "job_name = jobNameBase + '_array_all_{}-{}'.format( 0,n)\n",
    "slurm_filename = './slurm/'+job_name+'.slurm'\n",
    "array_slurm = open(slurm_filename, \"w+\")\n",
    "array_slurm.write(slurm_array_template.format(\n",
    "    job_name=job_name,\n",
    "    hours='36',\n",
    "    start=0,\n",
    "    stop=n,\n",
    "    WORK_DIR=WORK_DIR,\n",
    "    jobNameBase=jobNameBase\n",
    "))\n",
    "array_slurm.close()\n",
    "print(slurm_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now submit these with\n",
    "#qsub ./slurm/processCcd*.slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Run full patch\n",
    "Make one shell script and slurm script for each patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Copy HSC folders and make sky map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HSC preprocessed files must be copied into place (perhaps just the relevant tracts)\n",
    "#hsc_base = /Users/rs548/GitHub/lsst-ir-fusion/dmu0/dmu0_HSC/data/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-\n",
    "#hsc_target = data/rerun/coaddPhot/deepCoadd-results/HSC-\n",
    "#for band in ['G', 'I', 'Z', 'Y']:\n",
    "#    for tract in sxds_tracts: # [8282,8283,8284,8523,8524,8525,8765,8766,8767] \n",
    "#!cp -r \"{}{}/{}\".format(hsc_base,tract) target\n",
    "#Sky map must also be created\n",
    "#!makeSkyMap.py data --rerun processCcdOutputs:coadd --clobber-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_hsc_template = \"\"\"#!/bin/bash\n",
    "#Prepare Butler repo for processCcd and runPhotopipe slurm runs\n",
    "source /rfs/project/rfs-L33A9wsNuJk/shared/lsst_stack/loadLSST.bash\n",
    "setup lsst_distrib\n",
    "setup obs_vista\n",
    "eups admin clearLocks\n",
    "mkdir -p data/rerun/coaddPhot/deepCoadd-results/HSC-G\n",
    "mkdir -p data/rerun/coaddPhot/deepCoadd-results/HSC-R\n",
    "mkdir -p data/rerun/coaddPhot/deepCoadd-results/HSC-I\n",
    "mkdir -p data/rerun/coaddPhot/deepCoadd-results/HSC-Z\n",
    "mkdir -p data/rerun/coaddPhot/deepCoadd-results/HSC-Y\n",
    "makeSkyMap.py data --rerun processCcdOutputs:coadd --clobber-config\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSC='/home/ir-shir1/rds/rds-iris-ip005/data/public/HSC/hsc-release.mtk.nao.ac.jp/archive/filetree/pdr2_dud/deepCoadd-results/HSC-'\n",
    "TARGET='data/rerun/coaddPhot/deepCoadd-results/HSC-'\n",
    "job_name = \"setup_butler_repo\"\n",
    "f_sh = open('./' + job_name + '.sh', \"w+\")\n",
    "f_sh.write(cp_hsc_template)\n",
    "for band, tract in itertools.product(hsc_bands,sxds_tracts):\n",
    "    f_sh.write(\n",
    "        'cp -r {}/{} {} \\n'.format(HSC+band, tract, TARGET+band )\n",
    "    )\n",
    "f_sh.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Make shell files and array job for every patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sh_template = \"\"\"#!/bin/bash\n",
    "source /rfs/project/rfs-L33A9wsNuJk/shared/lsst_stack/loadLSST.bash\n",
    "setup lsst_distrib\n",
    "setup obs_vista\n",
    "eups admin clearLocks\n",
    "makeCoaddTempExp.py ../data --rerun coadd --selectId filter=VISTA-Y --id filter=VISTA-Y tract={tract} patch={patch} \n",
    "makeCoaddTempExp.py ../data --rerun coadd --selectId filter=VISTA-Ks --id filter=VISTA-J tract={tract} patch={patch} \n",
    "makeCoaddTempExp.py ../data --rerun coadd --selectId filter=VISTA-Y --id filter=VISTA-H tract={tract} patch={patch} \n",
    "makeCoaddTempExp.py ../data --rerun coadd --selectId filter=VISTA-Ks --id filter=VISTA-Ks tract={tract} patch={patch} \n",
    "\n",
    "assembleCoadd.py ../data --rerun coadd --selectId filter=VISTA-Y --id filter=VISTA-Y tract={tract} patch={patch}\n",
    "assembleCoadd.py ../data --rerun coadd --selectId filter=VISTA-Ks --id filter=VISTA-J tract={tract} patch={patch}\n",
    "assembleCoadd.py ../data --rerun coadd --selectId filter=VISTA-Y --id filter=VISTA-H tract={tract} patch={patch}\n",
    "assembleCoadd.py ../data --rerun coadd --selectId filter=VISTA-Ks --id filter=VISTA-Ks tract={tract} patch={patch}\n",
    "\n",
    "detectCoaddSources.py ../data --rerun coadd:coaddPhot --id filter=VISTA-Y tract={tract} patch={patch}\n",
    "detectCoaddSources.py ../data --rerun coadd:coaddPhot --id filter=VISTA-J tract={tract} patch={patch}\n",
    "detectCoaddSources.py ../data --rerun coadd:coaddPhot --id filter=VISTA-H tract={tract} patch={patch}\n",
    "detectCoaddSources.py ../data --rerun coadd:coaddPhot --id filter=VISTA-Ks tract={tract} patch={patch}\n",
    "\n",
    "#HSC files must be copied - Which bands to merge detections from?\n",
    "#mergeCoaddDetections.py ../data --rerun coaddPhot --id filter=VISTA-Y^VISTA-J^VISTA-H^VISTA-Ks^HSC-G^HSC-R^HSC-I^HSC-Z^HSC-Y tract={tract} patch={patch}\n",
    "mergeCoaddDetections.py ../data --rerun coaddPhot --id filter=VISTA-Ks tract={tract} patch={patch}\n",
    "\n",
    "deblendCoaddSources.py ../data --rerun coaddPhot --id filter=VISTA-Y tract={tract} patch={patch}\n",
    "deblendCoaddSources.py ../data --rerun coaddPhot --id filter=VISTA-J tract={tract} patch={patch}\n",
    "deblendCoaddSources.py ../data --rerun coaddPhot --id filter=VISTA-H tract={tract} patch={patch}\n",
    "deblendCoaddSources.py ../data --rerun coaddPhot --id filter=VISTA-Ks tract={tract} patch={patch}\n",
    "deblendCoaddSources.py ../data --rerun coaddPhot --id filter=HSC-G tract={tract} patch={patch}\n",
    "deblendCoaddSources.py ../data --rerun coaddPhot --id filter=HSC-R tract={tract} patch={patch}\n",
    "deblendCoaddSources.py ../data --rerun coaddPhot --id filter=HSC-I tract={tract} patch={patch}\n",
    "deblendCoaddSources.py ../data --rerun coaddPhot --id filter=HSC-Z tract={tract} patch={patch}\n",
    "deblendCoaddSources.py ../data --rerun coaddPhot --id filter=HSC-Y tract={tract} patch={patch}\n",
    "\n",
    "measureCoaddSources.py ../data --rerun coaddPhot --id filter=VISTA-Y tract={tract} patch={patch}\n",
    "measureCoaddSources.py ../data --rerun coaddPhot --id filter=VISTA-J tract={tract} patch={patch}\n",
    "measureCoaddSources.py ../data --rerun coaddPhot --id filter=VISTA-H tract={tract} patch={patch}\n",
    "measureCoaddSources.py ../data --rerun coaddPhot --id filter=VISTA-Ks tract={tract} patch={patch}\n",
    "measureCoaddSources.py ../data --rerun coaddPhot --id filter=HSC-G tract={tract} patch={patch}\n",
    "measureCoaddSources.py ../data --rerun coaddPhot --id filter=HSC-R tract={tract} patch={patch}\n",
    "measureCoaddSources.py ../data --rerun coaddPhot --id filter=HSC-I tract={tract} patch={patch}\n",
    "measureCoaddSources.py ../data --rerun coaddPhot --id filter=HSC-Z tract={tract} patch={patch}\n",
    "measureCoaddSources.py ../data --rerun coaddPhot --id filter=HSC-Y tract={tract} patch={patch}\n",
    "\n",
    "mergeCoaddMeasurements.py ../data --rerun coaddPhot --id filter=VISTA-Y^VISTA-J^VISTA-H^VISTA-Ks^HSC-G^HSC-R^HSC-I^HSC-Z^HSC-Y tract={tract} patch={patch}\n",
    "\n",
    "forcedPhotCoadd.py ../data --rerun coaddPhot:coaddForcedPhot --id filter=VISTA-Y tract={tract} patch={patch}\n",
    "forcedPhotCoadd.py ../data --rerun coaddForcedPhot --id filter=VISTA-J tract={tract} patch={patch}\n",
    "forcedPhotCoadd.py ../data --rerun coaddForcedPhot --id filter=VISTA-H tract={tract} patch={patch}\n",
    "forcedPhotCoadd.py ../data --rerun coaddForcedPhot --id filter=VISTA-Ks tract={tract} patch={patch}\n",
    "forcedPhotCoadd.py ../data --rerun coaddForcedPhot --id filter=HSC-G tract={tract} patch={patch}\n",
    "forcedPhotCoadd.py ../data --rerun coaddForcedPhot --id filter=HSC-R tract={tract} patch={patch}\n",
    "forcedPhotCoadd.py ../data --rerun coaddForcedPhot --id filter=HSC-I tract={tract} patch={patch}\n",
    "forcedPhotCoadd.py ../data --rerun coaddForcedPhot --id filter=HSC-Z tract={tract} patch={patch}\n",
    "forcedPhotCoadd.py ../data --rerun coaddForcedPhot --id filter=HSC-Y tract={tract} patch={patch}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for im in hsc_ims[in_sxds]:\n",
    "    tract = im['tract']\n",
    "    patch = im['patch']\n",
    "    job_name = \"runPhotoPipe_{}_{}_{}\".format(tract, patch, n)\n",
    "  \n",
    "    f_sh = open(\"./slurm/\"+job_name+\".sh\", \"w+\")\n",
    "    f_sh.write(patch_sh_template.format(tract=tract, patch=patch))\n",
    "    f_sh.close()\n",
    "    f_slurm = open(\"./slurm/\"+job_name+\".slurm\".format(tract, patch), \"w+\")\n",
    "    f_slurm.write(slurm_template.format(\n",
    "        job_name=job_name,\n",
    "        hours='5',\n",
    "        sh_name=WORK_DIR+\"/slurm/\"+job_name+\".sh\"\n",
    "        \n",
    "    ))\n",
    "    f_slurm.close()\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1629"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#make slurm jobs in batches\n",
    "block_size=50\n",
    "for block in range(int(np.ceil(n/block_size))):\n",
    "    start=block*block_size\n",
    "    stop =np.min([n+1, (block+1)*block_size]) -1\n",
    "    jobNameBase='runPhotoPipe'\n",
    "    job_name = jobNameBase + '_array_{}-{}'.format(start, stop)\n",
    "    slurm_filename = './slurm/'+job_name+'.slurm'\n",
    "    array_slurm = open(slurm_filename, \"w+\")\n",
    "    array_slurm.write(slurm_array_template.format(\n",
    "        job_name=job_name,\n",
    "        hours='36',\n",
    "        start=start,\n",
    "        stop=stop,\n",
    "        WORK_DIR=WORK_DIR,\n",
    "        jobNameBase=jobNameBase\n",
    "    ))\n",
    "    array_slurm.close()\n",
    "    print(slurm_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./slurm/runPhotoPipe_array_all_0-1629.slurm\n"
     ]
    }
   ],
   "source": [
    "#make one slurm job for all sh scripts\n",
    "start=0\n",
    "stop =n\n",
    "jobNameBase='runPhotoPipe'\n",
    "job_name = jobNameBase + '_array_all_{}-{}'.format(start, stop)\n",
    "slurm_filename = './slurm/'+job_name+'.slurm'\n",
    "array_slurm = open(slurm_filename, \"w+\")\n",
    "array_slurm.write(slurm_array_template.format(\n",
    "    job_name=job_name,\n",
    "    hours='36',\n",
    "    start=start,\n",
    "    stop=stop,\n",
    "    WORK_DIR=WORK_DIR,\n",
    "    jobNameBase=jobNameBase\n",
    "))\n",
    "array_slurm.close()\n",
    "print(slurm_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now submit these after the processCcd has run with\n",
    "#qsub ./slurm/patch*.slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
