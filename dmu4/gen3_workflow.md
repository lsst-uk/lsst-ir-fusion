# The Gen 3 Workflow

Running the pipeline at scale can not be performed with pipetask run but must instead use the Batch Processing System BPS:

https://pipelines.lsst.io/modules/lsst.ctrl.bps/quickstart.html

Running this using Slurm on CSD3 requires additional installations. Here I will try to include all the key communications I had with Jim Chiang regarding how to install and run this.

Some useful links:

- https://github.com/LSSTDESC/gen3_workflow/tree/master/python/desc/gen3_workflow
- https://github.com/LSSTDESC/gen3_workflow/wiki/Running-Gen-3-workflow-at-Cambridge

## Correspondence with Jim Chiang

Here are some slides of a tutorial I gave to a DESC working group back in November on running gen3 pipelines at NERSC using the parsl plugin:

https://docs.google.com/presentation/d/1EO_UBVhISBrBussCsIvJhNVxSnyfg5z6yIPaz99gA0A/edit#slide=id.gf546f83b40_0_52

On slide 11, it shows how I use the python interface directly to generate the QG and execution butler.  Doing that is essentially these python commands:

```Python
from desc.gen3_workflow import start_pipeline
graph = start_pipeline('bps_sfp.yaml')
```

I usually run that interactively since it uses just a single process, but it could be submitted as a job on a shared queue.  The problem is that it's not always clear how long it will take.    Once you have that graph object, you can find the output collection name generated by bps using

```Python
graph.config['outCollection']
```

With that info, I infer the location of the parsl_graph_config.pickle file and I generate a script to run rest of the workflow, e.g.,

```Shell
$ cat run_pipeline.py
import sys
from desc.gen3_workflow import ParslGraph

parsl_graph = 'submit/u/descdm/sfp_Y1_4430_visits_part_00/20211213T041900Z/parsl_graph_config.pickle'

parsl_config = dict(retries=1, monitoring=True, executor='WorkQueue',
                    provider='Local', nodes_per_block=10,
                    worker_options="--memory=87000")

graph = ParslGraph.restore(parsl_graph, parsl_config=parsl_config)

# Check if we are in an interactive shell, if not, then set block=True.
block = not sys.__stdin__.isatty()
graph.run(block=block)
I'd run this script instead of the bps submit command in the sbatch script:
#!/bin/bash
#SBATCH --job-name=sfp_4430_y1
#SBATCH --output=sfp_4430_y1.stdout
#SBATCH --error=sfp_4430_y1.stderr
#SBATCH --nodes=10
#SBATCH --time=15:00:00
#SBATCH --constraint=knl
#SBATCH --qos=regular
#SBATCH --exclusive
#SBATCH --account=m1727

cd /global/cscratch1/sd/descdm/Gen3/Run2.2i/SFP/4430
source ../../setup.sh
python run_pipeline.py
```
